{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPNHzyBEKmjB6ojgcMKYWMy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jayjoshina/Soc-project/blob/main/Soc_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ior5ihg0NE70"
      },
      "outputs": [],
      "source": [
        "words = open('names.txt', 'r').read().splitlines()\n",
        "import torch\n",
        "\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "xs, ys = [], []\n",
        "\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2,ch3 in zip(chs, chs[1:],chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    ix3=stoi[ch3]\n",
        "\n",
        "    xs.append([ix1,ix2])\n",
        "    ys.append(ix3)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M2QFe4fP0gF",
        "outputId": "eb7c3f2f-7539-4370-a2e0-76eb041130e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preparing dataset for bigram model from same dataset\n",
        "x2, y2 = [], []\n",
        "\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "\n",
        "\n",
        "    x2.append(ix1)\n",
        "    y2.append(ix2)\n",
        "\n",
        "x2 = torch.tensor(x2)\n",
        "y2 = torch.tensor(y2)\n"
      ],
      "metadata": {
        "id": "DcVqetqfIAwG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Manually doing one hot encoding\n",
        "import numpy as np\n",
        "x1=[]\n",
        "for i in range(xs.shape[0]):\n",
        "  b=np.zeros((27))\n",
        "  b[xs[i][0].item()]=1\n",
        "  b[xs[i][1].item()]=1\n",
        "  x1.append(b)\n",
        "x1=torch.tensor(x1, dtype=torch.float32)\n",
        "\n",
        "x1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTjgvcPfR4cP",
        "outputId": "5aa75551-bc0d-4668-e501-13d72599e8f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-1c574b732b8f>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  x1=torch.tensor(x1, dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 1., 1.],\n",
              "        [0., 0., 0.,  ..., 0., 1., 1.],\n",
              "        [0., 0., 0.,  ..., 1., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encoding for biagram model dataset\n",
        "x3=torch.nn.functional.one_hot(x2, num_classes=27).float()\n",
        "x3.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_ZRpe32Id56",
        "outputId": "0f2f6e95-b922-4051-8ecd-180cc1099262"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting data into test,dev,train\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_ratio=0.8\n",
        "test_ratio=0.1\n",
        "validation_ratio=0.1\n",
        "\n",
        "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, ys, test_size=1 - train_ratio)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 10% of the initial data set\n",
        "x1_val, x1_test, y1_val, y1_test = train_test_split(x1_test, y1_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
        "\n",
        "x2_train, x2_test, y2_train, y2_test = train_test_split(x3, y2, test_size=1 - train_ratio)\n",
        "x2_val, x2_test, y2_val, y2_test = train_test_split(x2_test, y2_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
        "\n",
        "\n",
        "#y2_train=y2_train.view((y2_train.shape[0],1))\n",
        "x2_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6aVvpU8JklE",
        "outputId": "44894654-ed24-49bd-c4c6-57dde8ae0585"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([22815, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trigram model training\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True)\n",
        "for k in range(20):    #20 epochs\n",
        "\n",
        "  # forward pass\n",
        "\n",
        "  logits = x1_train @ W # predict log-counts\n",
        "  loss= torch.nn.functional.cross_entropy(logits,y1_train)\n",
        "  print(loss.item())\n",
        "\n",
        "  # backward pass\n",
        "  W.grad = None # set to zero the gradient\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  W.data += -10 * W.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQTYoA_jUGs8",
        "outputId": "3c10d5ed-63c3-4752-a348-07b04b31a6b7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.12053108215332\n",
            "3.846113443374634\n",
            "3.638129472732544\n",
            "3.4788100719451904\n",
            "3.3536806106567383\n",
            "3.2538304328918457\n",
            "3.1734867095947266\n",
            "3.108009099960327\n",
            "3.0536139011383057\n",
            "3.007500171661377\n",
            "2.9677295684814453\n",
            "2.932969093322754\n",
            "2.902269124984741\n",
            "2.87492299079895\n",
            "2.85038685798645\n",
            "2.8282315731048584\n",
            "2.808112382888794\n",
            "2.7897489070892334\n",
            "2.7729105949401855\n",
            "2.7574069499969482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking loss on validation set\n",
        "with torch.no_grad():\n",
        " logits_val1 = x1_val @ W # predict log-counts\n",
        " loss1_val = torch.nn.functional.cross_entropy(logits_val1,y1_val)\n",
        "print(loss1_val.item())\n",
        "\n",
        "# loss almost saturates after learning rate of 10,so this is the min loss we can get and also loss of train and validation sets are almost equal so there is no overfitting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYlpW9HBOJcd",
        "outputId": "7106a9e2-535c-47f6-be31-29a5a741fcc8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7451260089874268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        " logits_test1 = x1_test @ W\n",
        " _,y1_pred=torch.max(logits_test1,1)\n",
        " acc=(y1_pred==y1_test).sum()\n",
        "print(acc.item()/x1_test.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebo3RJyjG979",
        "outputId": "51dac6e5-e5fe-474c-a1d4-d053af145969"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2234346318580461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bigram model training\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W2 = torch.randn((27, 27), generator=g, requires_grad=True)\n",
        "for k in range(200):    #20 epochs\n",
        "\n",
        "  # forward pass\n",
        "\n",
        "  logits2 = x2_train @ W2 # predict log-counts\n",
        "  #counts = logits.exp() # counts, equivalent to N\n",
        "  #probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "  loss2 = torch.nn.functional.cross_entropy(logits2,y2_train)\n",
        "\n",
        "\n",
        "  # backward pass\n",
        "  W2.grad = None # set to zero the gradient\n",
        "  loss2.backward()\n",
        "\n",
        "  # update\n",
        "  W2.data += -10 * W2.grad\n",
        "print(loss2.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvEPikyeMkvf",
        "outputId": "fcfad399-dd4d-42dd-e6ad-ef4a52bc7e86"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5109479427337646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking loss on validation set\n",
        "with torch.no_grad():\n",
        " logits_val2 = x2_val @ W2 # predict log-counts\n",
        " loss2_val = torch.nn.functional.cross_entropy(logits_val2,y2_val)\n",
        "print(loss2_val.item())\n",
        "\n",
        "# loss almost saturates after learning rate of 10,so this is the min loss we can get and also loss of train and validation sets are almost equal so there is no overfitting"
      ],
      "metadata": {
        "id": "8FbCuGaDQZKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bbdb149-504c-4928-88e4-425fba99f423"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5055418014526367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        " logits_test2 = x2_test @ W2\n",
        " _,y2_pred=torch.max(logits_test2,1)\n",
        " acc=(y2_pred==y2_test).sum()\n",
        "print(acc.item()/x2_test.shape[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIdLliMHI-5w",
        "outputId": "9435d8bd-a66d-4a34-a739-b5c0d6d70d2c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.225290379136533\n"
          ]
        }
      ]
    }
  ]
}